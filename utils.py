# Copyright Niantic 2019. Patent Pending. All rights reserved.
#
# This software is licensed under the terms of the Monodepth2 licence
# which allows for non-commercial use only, the full terms of which are made
# available in the LICENSE file.

from __future__ import absolute_import, division, print_function

import os, shutil
import hashlib
import zipfile
import numpy as np
from six.moves import urllib

def meshgrid(x, y, indexing):
    # only for planedepth,if you don't use planedepth,ignore it
    grid_y, grid_x = torch.meshgrid(y, x)
    return (grid_x, grid_y)
def save_code(srcfile, log_path):
    #save depth_decoder.py to log, easy to evaluation
    #srcfile = "./networks/depth_decoder.py"
    if not os.path.isfile(srcfile):
        print ("%s not exist!"%(srcfile))
    else:
        fpath,fname=os.path.split(srcfile)
        if not os.path.exists(log_path):
            os.makedirs(log_path)
        shutil.copy(srcfile, os.path.join(log_path, fname))
        print ("copy %s -> %s"%(srcfile, os.path.join(log_path, fname)))

def readlines(filename):
    """Read all the lines in a text file and return as a list
    """
    with open(filename, 'r') as f:
        lines = f.read().splitlines()
    return lines


def normalize_image(x):
    """Rescale image pixels to span range [0, 1]
    """
    ma = float(x.max().cpu().data)
    mi = float(x.min().cpu().data)
    d = ma - mi if ma != mi else 1e5
    return (x - mi) / d


def sec_to_hm(t):
    """Convert time in seconds to time in hours, minutes and seconds
    e.g. 10239 -> (2, 50, 39)
    """
    t = int(t)
    s = t % 60
    t //= 60
    m = t % 60
    t //= 60
    return t, m, s


def sec_to_hm_str(t):
    """Convert time in seconds to a nice string
    e.g. 10239 -> '02h50m39s'
    """
    h, m, s = sec_to_hm(t)
    return "{:02d}h{:02d}m{:02d}s".format(h, m, s)


def download_model_if_doesnt_exist(model_name):
    """If pretrained kitti model doesn't exist, download and unzip it
    """
    # values are tuples of (<google cloud URL>, <md5 checksum>)
    download_paths = {
        "mono_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono_640x192.zip",
             "a964b8356e08a02d009609d9e3928f7c"),
        "stereo_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/stereo_640x192.zip",
             "3dfb76bcff0786e4ec07ac00f658dd07"),
        "mono+stereo_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono%2Bstereo_640x192.zip",
             "c024d69012485ed05d7eaa9617a96b81"),
        "mono_no_pt_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono_no_pt_640x192.zip",
             "9c2f071e35027c895a4728358ffc913a"),
        "stereo_no_pt_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/stereo_no_pt_640x192.zip",
             "41ec2de112905f85541ac33a854742d1"),
        "mono+stereo_no_pt_640x192":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono%2Bstereo_no_pt_640x192.zip",
             "46c3b824f541d143a45c37df65fbab0a"),
        "mono_1024x320":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono_1024x320.zip",
             "0ab0766efdfeea89a0d9ea8ba90e1e63"),
        "stereo_1024x320":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/stereo_1024x320.zip",
             "afc2f2126d70cf3fdf26b550898b501a"),
        "mono+stereo_1024x320":
            ("https://storage.googleapis.com/niantic-lon-static/research/monodepth2/mono%2Bstereo_1024x320.zip",
             "cdc5fc9b23513c07d5b19235d9ef08f7"),
        }

    if not os.path.exists("models"):
        os.makedirs("models")

    model_path = os.path.join("models", model_name)

    def check_file_matches_md5(checksum, fpath):
        if not os.path.exists(fpath):
            return False
        with open(fpath, 'rb') as f:
            current_md5checksum = hashlib.md5(f.read()).hexdigest()
        return current_md5checksum == checksum

    # see if we have the model already downloaded...
    if not os.path.exists(os.path.join(model_path, "encoder.pth")):

        model_url, required_md5checksum = download_paths[model_name]

        if not check_file_matches_md5(required_md5checksum, model_path + ".zip"):
            print("-> Downloading pretrained model to {}".format(model_path + ".zip"))
            urllib.request.urlretrieve(model_url, model_path + ".zip")

        if not check_file_matches_md5(required_md5checksum, model_path + ".zip"):
            print("   Failed to download a file which matches the checksum - quitting")
            quit()

        print("   Unzipping model...")
        with zipfile.ZipFile(model_path + ".zip", 'r') as f:
            f.extractall(model_path)

        print("   Model unzipped to {}".format(model_path))


import collections
from torch._six import string_classes
import re
import torch

np_str_obj_array_pattern = re.compile(r'[SaUO]')#正则表达式，用于匹配 numpy 数组中的字符串和对象类型
default_collate_err_msg_format = (
    "default_collate: batch must contain tensors, numpy arrays, numbers, "
    "dicts or lists; found {}")#错误消息格式字符串，用于在出现错误时打印错误消息,说白了规定了必须是这些类型的数据

def rmnone_collate(batch):
    """踢出空值"""
    batch_new = []
    for v in batch:
        if v is not None:
            batch_new.append(v)
    batch = batch_new
    if len(batch) == 0:
        return None
    else:
        return default_collate(batch)

def default_collate(batch):
    r"""将每个数据字段放入具有外部维度批大小的张量中"""
    elem = batch[0]
    elem_type = type(elem)
    if isinstance(elem, torch.Tensor):
        out = None
        # PyTorch 张量则函数会使用 torch.stack 函数将整个批量数据 batch 合并成一个张量
        if torch.utils.data.get_worker_info() is not None:
            # 果我们处于后台进程中，请直接连接到共享内存张量以避免额外的副本
            numel = sum(x.numel() for x in batch)
            storage = elem.storage()._new_shared(numel)
            out = elem.new(storage)
        return torch.stack(batch, 0, out=out)
    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \
            and elem_type.__name__ != 'string_':
        #numpy 数组则转换为 torch 张量，递归
        if elem_type.__name__ == 'ndarray' or elem_type.__name__ == 'memmap':
            # array of string classes and object
            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:
                raise TypeError(default_collate_err_msg_format.format(elem.dtype))

            return default_collate([torch.as_tensor(b) for b in batch])
        elif elem.shape == ():  # scalars
            return torch.as_tensor(batch)
    elif isinstance(elem, float):
        return torch.tensor(batch, dtype=torch.float64)
    elif isinstance(elem, int):
        return torch.tensor(batch)
    elif isinstance(elem, string_classes):
        return batch
    elif isinstance(elem, collections.abc.Mapping):
        return {key: default_collate([d[key] for d in batch]) for key in elem}
    elif isinstance(elem, tuple) and hasattr(elem, '_fields'):  # namedtuple
        return elem_type(*(default_collate(samples) for samples in zip(*batch)))
    elif isinstance(elem, collections.abc.Sequence):
        # check to make sure that the elements in batch have consistent size
        it = iter(batch)
        elem_size = len(next(it))
        if not all(len(elem) == elem_size for elem in it):
            raise RuntimeError('each element in list of batch should be of equal size')
        transposed = zip(*batch)
        return [default_collate(samples) for samples in transposed]

    raise TypeError(default_collate_err_msg_format.format(elem_type))

def preprocess_image(image, delta=0.01, x_length=40, y_length=35):
    # image should be float between [0, 1] with size HWC
    new_image = image.copy()
    H, W, C = image.shape
    flaging = False
    for y in range(H):
        for x in range(W-1):
            if np.abs((image[y, x] - image[y, x+1])).sum() < delta:
                if not flaging:
                    flaging = True
                    start_x = x
            else:
                if flaging:
                    flaging = False
                    end_x = x
                    if (end_x - start_x) > x_length:
                        encoding = np.linspace(0, 1, end_x - start_x + 1)
                        # color = image[y, start_x:end_x+1, :].mean()
                        new_image[y, start_x:end_x+1, 0] = (encoding + image[y, start_x:end_x+1, 0]) / 2
                        # new_image[y, start_x:end_x+1, 2] = color
        flaging = False
        start_x = 0
        
    for x in range(W):
        for y in range(H-1):
            if np.abs((image[y, x] - image[y+1, x])).sum() < delta:
                if not flaging:
                    flaging = True
                    start_y = y
            else:
                if flaging:
                    flaging = False
                    end_y = y
                    if (end_y - start_y) > y_length:
                        encoding = np.linspace(0, 1, end_y - start_y + 1)
                        # color = image[start_y:end_y+1, x, :].mean()
                        new_image[start_y:end_y+1, x, 1] = (encoding + image[start_y:end_y+1, x, 1]) / 2
                        # new_image[start_y:end_y+1, x, 2] = (new_image[start_y:end_y+1, x, 2] + color) / 2
        flaging = False
        start_y = 0
    return new_image